{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImBlurryF4c3/AnomalySegmentation_CourseProjectBaseCode/blob/fede/Training_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie-yUdgofaIY",
        "outputId": "5c7ba0db-bc1f-44ed-bd11-31e0f4a39382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AnomalySegmentation_CourseProjectBaseCode'...\n",
            "remote: Enumerating objects: 4128, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 4128 (delta 79), reused 154 (delta 72), pack-reused 3964\u001b[K\n",
            "Receiving objects: 100% (4128/4128), 1.93 GiB | 41.45 MiB/s, done.\n",
            "Resolving deltas: 100% (887/887), done.\n",
            "Updating files: 100% (3507/3507), done.\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/AnomalySegmentation_CourseProjectBaseCode\n",
            "Updating files: 100% (75/75), done.\n",
            "Branch 'fede' set up to track remote branch 'fede' from 'origin'.\n",
            "Switched to a new branch 'fede'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ImBlurryF4c3/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "%cd AnomalySegmentation_CourseProjectBaseCode\n",
        "!git checkout fede\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hElHgibsiaFJ",
        "outputId": "a3634257-12c9-44a5-eff1-698649729da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom) (6.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom) (1.16.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.10/dist-packages (from visdom) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom) (1.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from visdom) (3.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom) (9.4.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch->visdom) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/\n",
        "!pip install visdom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Pu4KtRDyMI",
        "outputId": "52d4ad5e-1479-4d7f-f00d-ae4ef8ccff82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Cityscapes_training’: File exists\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n"
          ]
        }
      ],
      "source": [
        "%mkdir Cityscapes_training\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Icz1UFxluMj",
        "outputId": "af1b0b05-bcf4-4aa6-f1ed-fea852a8c979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n",
            "Requirement already satisfied: cityscapesscripts in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (9.4.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (1.4.4)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (0.9.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (15.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (4.66.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (from cityscapesscripts) (3.7.4.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->cityscapesscripts) (10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cityscapesscripts) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->cityscapesscripts) (1.16.0)\n",
            "Downloading cityscapes package 'leftImg8bit_trainvaltest.zip' to './leftImg8bit_trainvaltest.zip'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/csDownload\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cityscapesscripts/download/downloader.py\", line 165, in main\n",
            "    download_packages(session=session, package_names=args.package_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cityscapesscripts/download/downloader.py\", line 105, in download_packages\n",
            "    raise Exception(\n",
            "Exception: Destination file './leftImg8bit_trainvaltest.zip' already exists.\n",
            "Downloading cityscapes package 'gtFine_trainvaltest.zip' to './gtFine_trainvaltest.zip'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/csDownload\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cityscapesscripts/download/downloader.py\", line 165, in main\n",
            "    download_packages(session=session, package_names=args.package_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cityscapesscripts/download/downloader.py\", line 105, in download_packages\n",
            "    raise Exception(\n",
            "Exception: Destination file './gtFine_trainvaltest.zip' already exists.\n",
            "Archive:  leftImg8bit_trainvaltest.zip\n",
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace license.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace leftImg8bit/train/jena/jena_000078_000019_leftImg8bit.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  gtFine_trainvaltest.zip\n",
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n",
        " #Download Cityscapes Dataset\n",
        "!python -m pip install cityscapesscripts\n",
        "!csDownload leftImg8bit_trainvaltest.zip\n",
        "!csDownload gtFine_trainvaltest.zip\n",
        "\n",
        "!unzip leftImg8bit_trainvaltest.zip\n",
        "!unzip gtFine_trainvaltest.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TAh_lhct88j"
      },
      "outputs": [],
      "source": [
        "!cd /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n",
        "%rm -r /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhD3k6mrEq5_",
        "outputId": "42172f04-8232-4bfe-9508-6671d51c27f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n",
            "Processing 5000 annotation files\n",
            "Progress: 7.34 % "
          ]
        }
      ],
      "source": [
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training\n",
        "!CITYSCAPES_DATASET='.' csCreateTrainIdLabelImgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4-5Fsomfzok",
        "outputId": "5ee0f0f6-31f2-4d50-9645-7fda16b73a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/train\n",
            "========== ENCODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:248: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  weight = torch.tensor(weights)\n",
            "calcolo loader\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "fine loader_val\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:222: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
            "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 2.995 (epoch: 1, step: 0) // Avg time/img: 0.7616 s\n",
            "loss: 2.984 (epoch: 1, step: 50) // Avg time/img: 0.1445 s\n",
            "loss: 2.98 (epoch: 1, step: 100) // Avg time/img: 0.1378 s\n",
            "loss: 2.978 (epoch: 1, step: 150) // Avg time/img: 0.1359 s\n",
            "loss: 2.976 (epoch: 1, step: 200) // Avg time/img: 0.1347 s\n",
            "loss: 2.975 (epoch: 1, step: 250) // Avg time/img: 0.1340 s\n",
            "loss: 2.975 (epoch: 1, step: 300) // Avg time/img: 0.1336 s\n",
            "loss: 2.974 (epoch: 1, step: 350) // Avg time/img: 0.1333 s\n",
            "loss: 2.973 (epoch: 1, step: 400) // Avg time/img: 0.1330 s\n",
            "loss: 2.972 (epoch: 1, step: 450) // Avg time/img: 0.1328 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:460: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:461: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  targets = Variable(labels, volatile=True)\n",
            "2.9659438133239746\n",
            "1\n",
            "VAL loss: 2.966 (epoch: 1, step: 0) // Avg time/img: 0.1649 s\n",
            "151.70600128173828\n",
            "51\n",
            "VAL loss: 2.975 (epoch: 1, step: 50) // Avg time/img: 0.1293 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m18.55\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 2.967 (epoch: 2, step: 0) // Avg time/img: 0.1419 s\n",
            "loss: 2.966 (epoch: 2, step: 50) // Avg time/img: 0.1316 s\n",
            "loss: 2.965 (epoch: 2, step: 100) // Avg time/img: 0.1311 s\n",
            "loss: 2.965 (epoch: 2, step: 150) // Avg time/img: 0.1310 s\n",
            "loss: 2.964 (epoch: 2, step: 200) // Avg time/img: 0.1310 s\n",
            "loss: 2.964 (epoch: 2, step: 250) // Avg time/img: 0.1310 s\n",
            "loss: 2.963 (epoch: 2, step: 300) // Avg time/img: 0.1309 s\n",
            "loss: 2.963 (epoch: 2, step: 350) // Avg time/img: 0.1309 s\n",
            "loss: 2.963 (epoch: 2, step: 400) // Avg time/img: 0.1309 s\n",
            "loss: 2.962 (epoch: 2, step: 450) // Avg time/img: 0.1309 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "2.952457904815674\n",
            "1\n",
            "VAL loss: 2.952 (epoch: 2, step: 0) // Avg time/img: 0.1399 s\n",
            "151.18988752365112\n",
            "51\n",
            "VAL loss: 2.965 (epoch: 2, step: 50) // Avg time/img: 0.1285 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m23.17\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 2.952 (epoch: 3, step: 0) // Avg time/img: 0.1458 s\n",
            "loss: 2.96 (epoch: 3, step: 50) // Avg time/img: 0.1320 s\n",
            "loss: 2.959 (epoch: 3, step: 100) // Avg time/img: 0.1316 s\n",
            "loss: 2.959 (epoch: 3, step: 150) // Avg time/img: 0.1311 s\n",
            "loss: 2.958 (epoch: 3, step: 200) // Avg time/img: 0.1309 s\n",
            "loss: 2.958 (epoch: 3, step: 250) // Avg time/img: 0.1309 s\n",
            "loss: 2.958 (epoch: 3, step: 300) // Avg time/img: 0.1308 s\n",
            "loss: 2.958 (epoch: 3, step: 350) // Avg time/img: 0.1308 s\n",
            "loss: 2.958 (epoch: 3, step: 400) // Avg time/img: 0.1308 s\n",
            "loss: 2.958 (epoch: 3, step: 450) // Avg time/img: 0.1307 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "2.9518961906433105\n",
            "1\n",
            "VAL loss: 2.952 (epoch: 3, step: 0) // Avg time/img: 0.1390 s\n",
            "151.03074622154236\n",
            "51\n",
            "VAL loss: 2.961 (epoch: 3, step: 50) // Avg time/img: 0.1281 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m26.39\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 2.976 (epoch: 4, step: 0) // Avg time/img: 0.1429 s\n",
            "loss: 2.956 (epoch: 4, step: 50) // Avg time/img: 0.1308 s\n",
            "loss: 2.955 (epoch: 4, step: 100) // Avg time/img: 0.1304 s\n",
            "loss: 2.955 (epoch: 4, step: 150) // Avg time/img: 0.1302 s\n",
            "loss: 2.954 (epoch: 4, step: 200) // Avg time/img: 0.1303 s\n",
            "loss: 2.954 (epoch: 4, step: 250) // Avg time/img: 0.1302 s\n",
            "loss: 2.954 (epoch: 4, step: 300) // Avg time/img: 0.1302 s\n",
            "loss: 2.954 (epoch: 4, step: 350) // Avg time/img: 0.1302 s\n",
            "loss: 2.954 (epoch: 4, step: 400) // Avg time/img: 0.1302 s\n",
            "loss: 2.954 (epoch: 4, step: 450) // Avg time/img: 0.1303 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "2.976440906524658\n",
            "1\n",
            "VAL loss: 2.976 (epoch: 4, step: 0) // Avg time/img: 0.1392 s\n",
            "151.1369264125824\n",
            "51\n",
            "VAL loss: 2.963 (epoch: 4, step: 50) // Avg time/img: 0.1278 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m21.55\u001b[0m %\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 2.97 (epoch: 5, step: 0) // Avg time/img: 0.1413 s\n",
            "loss: 2.952 (epoch: 5, step: 50) // Avg time/img: 0.1308 s\n",
            "loss: 2.952 (epoch: 5, step: 100) // Avg time/img: 0.1306 s\n",
            "loss: 2.951 (epoch: 5, step: 150) // Avg time/img: 0.1304 s\n",
            "loss: 2.951 (epoch: 5, step: 200) // Avg time/img: 0.1304 s\n",
            "loss: 2.951 (epoch: 5, step: 250) // Avg time/img: 0.1303 s\n",
            "loss: 2.951 (epoch: 5, step: 300) // Avg time/img: 0.1303 s\n",
            "loss: 2.951 (epoch: 5, step: 350) // Avg time/img: 0.1303 s\n",
            "loss: 2.951 (epoch: 5, step: 400) // Avg time/img: 0.1303 s\n",
            "loss: 2.951 (epoch: 5, step: 450) // Avg time/img: 0.1302 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "2.9438586235046387\n",
            "1\n",
            "VAL loss: 2.944 (epoch: 5, step: 0) // Avg time/img: 0.1387 s\n",
            "150.6493444442749\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 5, step: 50) // Avg time/img: 0.1285 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.95\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 2.963 (epoch: 6, step: 0) // Avg time/img: 0.1392 s\n",
            "loss: 2.948 (epoch: 6, step: 50) // Avg time/img: 0.1308 s\n",
            "loss: 2.948 (epoch: 6, step: 100) // Avg time/img: 0.1302 s\n",
            "loss: 2.949 (epoch: 6, step: 150) // Avg time/img: 0.1301 s\n",
            "loss: 2.949 (epoch: 6, step: 200) // Avg time/img: 0.1302 s\n",
            "loss: 2.949 (epoch: 6, step: 250) // Avg time/img: 0.1302 s\n",
            "loss: 2.949 (epoch: 6, step: 300) // Avg time/img: 0.1301 s\n",
            "loss: 2.948 (epoch: 6, step: 350) // Avg time/img: 0.1301 s\n",
            "loss: 2.949 (epoch: 6, step: 400) // Avg time/img: 0.1301 s\n",
            "loss: 2.948 (epoch: 6, step: 450) // Avg time/img: 0.1302 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "2.9452779293060303\n",
            "1\n",
            "VAL loss: 2.945 (epoch: 6, step: 0) // Avg time/img: 0.1412 s\n",
            "150.61587500572205\n",
            "51\n",
            "VAL loss: 2.953 (epoch: 6, step: 50) // Avg time/img: 0.1279 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.29\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 2.946 (epoch: 7, step: 0) // Avg time/img: 0.1444 s\n",
            "loss: 2.947 (epoch: 7, step: 50) // Avg time/img: 0.1312 s\n",
            "loss: 2.947 (epoch: 7, step: 100) // Avg time/img: 0.1307 s\n",
            "loss: 2.947 (epoch: 7, step: 150) // Avg time/img: 0.1305 s\n",
            "loss: 2.947 (epoch: 7, step: 200) // Avg time/img: 0.1304 s\n",
            "loss: 2.947 (epoch: 7, step: 250) // Avg time/img: 0.1303 s\n",
            "loss: 2.947 (epoch: 7, step: 300) // Avg time/img: 0.1302 s\n",
            "loss: 2.947 (epoch: 7, step: 350) // Avg time/img: 0.1302 s\n",
            "loss: 2.947 (epoch: 7, step: 400) // Avg time/img: 0.1302 s\n",
            "loss: 2.947 (epoch: 7, step: 450) // Avg time/img: 0.1301 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "2.949601173400879\n",
            "1\n",
            "VAL loss: 2.95 (epoch: 7, step: 0) // Avg time/img: 0.1355 s\n",
            "150.6289472579956\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 7, step: 50) // Avg time/img: 0.1276 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.41\u001b[0m %\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 2.942 (epoch: 8, step: 0) // Avg time/img: 0.1427 s\n",
            "loss: 2.946 (epoch: 8, step: 50) // Avg time/img: 0.1313 s\n",
            "loss: 2.946 (epoch: 8, step: 100) // Avg time/img: 0.1304 s\n",
            "loss: 2.946 (epoch: 8, step: 150) // Avg time/img: 0.1302 s\n",
            "loss: 2.946 (epoch: 8, step: 200) // Avg time/img: 0.1301 s\n",
            "loss: 2.946 (epoch: 8, step: 250) // Avg time/img: 0.1302 s\n",
            "loss: 2.946 (epoch: 8, step: 300) // Avg time/img: 0.1302 s\n",
            "loss: 2.946 (epoch: 8, step: 350) // Avg time/img: 0.1302 s\n",
            "loss: 2.945 (epoch: 8, step: 400) // Avg time/img: 0.1301 s\n",
            "loss: 2.945 (epoch: 8, step: 450) // Avg time/img: 0.1301 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "2.950714111328125\n",
            "1\n",
            "VAL loss: 2.951 (epoch: 8, step: 0) // Avg time/img: 0.1370 s\n",
            "150.4722752571106\n",
            "51\n",
            "VAL loss: 2.95 (epoch: 8, step: 50) // Avg time/img: 0.1279 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.69\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 2.938 (epoch: 9, step: 0) // Avg time/img: 0.1386 s\n",
            "loss: 2.943 (epoch: 9, step: 50) // Avg time/img: 0.1309 s\n",
            "loss: 2.943 (epoch: 9, step: 100) // Avg time/img: 0.1302 s\n",
            "loss: 2.943 (epoch: 9, step: 150) // Avg time/img: 0.1303 s\n",
            "loss: 2.943 (epoch: 9, step: 200) // Avg time/img: 0.1302 s\n",
            "loss: 2.943 (epoch: 9, step: 250) // Avg time/img: 0.1301 s\n",
            "loss: 2.943 (epoch: 9, step: 300) // Avg time/img: 0.1302 s\n",
            "loss: 2.943 (epoch: 9, step: 350) // Avg time/img: 0.1302 s\n",
            "loss: 2.943 (epoch: 9, step: 400) // Avg time/img: 0.1303 s\n",
            "loss: 2.944 (epoch: 9, step: 450) // Avg time/img: 0.1303 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "2.942474365234375\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 9, step: 0) // Avg time/img: 0.1384 s\n",
            "150.31297087669373\n",
            "51\n",
            "VAL loss: 2.947 (epoch: 9, step: 50) // Avg time/img: 0.1281 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m34.50\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 2.937 (epoch: 10, step: 0) // Avg time/img: 0.1429 s\n",
            "loss: 2.941 (epoch: 10, step: 50) // Avg time/img: 0.1313 s\n",
            "loss: 2.941 (epoch: 10, step: 100) // Avg time/img: 0.1307 s\n",
            "loss: 2.942 (epoch: 10, step: 150) // Avg time/img: 0.1304 s\n",
            "loss: 2.942 (epoch: 10, step: 200) // Avg time/img: 0.1304 s\n",
            "loss: 2.942 (epoch: 10, step: 250) // Avg time/img: 0.1303 s\n",
            "loss: 2.942 (epoch: 10, step: 300) // Avg time/img: 0.1304 s\n",
            "loss: 2.942 (epoch: 10, step: 350) // Avg time/img: 0.1303 s\n",
            "loss: 2.942 (epoch: 10, step: 400) // Avg time/img: 0.1303 s\n",
            "loss: 2.942 (epoch: 10, step: 450) // Avg time/img: 0.1303 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "2.9422619342803955\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 10, step: 0) // Avg time/img: 0.1406 s\n",
            "150.25516295433044\n",
            "51\n",
            "VAL loss: 2.946 (epoch: 10, step: 50) // Avg time/img: 0.1287 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m35.03\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_encoder_best.pth (epoch: 10)\n",
            "========== DECODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "fine loader_val\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 2.995 (epoch: 1, step: 0) // Avg time/img: 0.1977 s\n",
            "loss: 2.99 (epoch: 1, step: 50) // Avg time/img: 0.1752 s\n",
            "loss: 2.986 (epoch: 1, step: 100) // Avg time/img: 0.1733 s\n",
            "loss: 2.982 (epoch: 1, step: 150) // Avg time/img: 0.1726 s\n",
            "loss: 2.979 (epoch: 1, step: 200) // Avg time/img: 0.1721 s\n",
            "loss: 2.977 (epoch: 1, step: 250) // Avg time/img: 0.1718 s\n",
            "loss: 2.975 (epoch: 1, step: 300) // Avg time/img: 0.1714 s\n",
            "loss: 2.973 (epoch: 1, step: 350) // Avg time/img: 0.1711 s\n",
            "loss: 2.972 (epoch: 1, step: 400) // Avg time/img: 0.1710 s\n",
            "loss: 2.971 (epoch: 1, step: 450) // Avg time/img: 0.1709 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "2.953472852706909\n",
            "1\n",
            "VAL loss: 2.953 (epoch: 1, step: 0) // Avg time/img: 0.1887 s\n",
            "151.2197482585907\n",
            "51\n",
            "VAL loss: 2.965 (epoch: 1, step: 50) // Avg time/img: 0.1646 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m21.00\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 2.959 (epoch: 2, step: 0) // Avg time/img: 0.1854 s\n",
            "loss: 2.957 (epoch: 2, step: 50) // Avg time/img: 0.1707 s\n",
            "loss: 2.958 (epoch: 2, step: 100) // Avg time/img: 0.1699 s\n",
            "loss: 2.957 (epoch: 2, step: 150) // Avg time/img: 0.1696 s\n",
            "loss: 2.956 (epoch: 2, step: 200) // Avg time/img: 0.1695 s\n",
            "loss: 2.956 (epoch: 2, step: 250) // Avg time/img: 0.1694 s\n",
            "loss: 2.956 (epoch: 2, step: 300) // Avg time/img: 0.1692 s\n",
            "loss: 2.955 (epoch: 2, step: 350) // Avg time/img: 0.1691 s\n",
            "loss: 2.955 (epoch: 2, step: 400) // Avg time/img: 0.1691 s\n",
            "loss: 2.955 (epoch: 2, step: 450) // Avg time/img: 0.1690 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "2.9504992961883545\n",
            "1\n",
            "VAL loss: 2.95 (epoch: 2, step: 0) // Avg time/img: 0.1839 s\n",
            "150.84524083137512\n",
            "51\n",
            "VAL loss: 2.958 (epoch: 2, step: 50) // Avg time/img: 0.1640 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m25.45\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 2.954 (epoch: 3, step: 0) // Avg time/img: 0.1806 s\n",
            "loss: 2.95 (epoch: 3, step: 50) // Avg time/img: 0.1698 s\n",
            "loss: 2.951 (epoch: 3, step: 100) // Avg time/img: 0.1689 s\n",
            "loss: 2.952 (epoch: 3, step: 150) // Avg time/img: 0.1688 s\n",
            "loss: 2.952 (epoch: 3, step: 200) // Avg time/img: 0.1686 s\n",
            "loss: 2.952 (epoch: 3, step: 250) // Avg time/img: 0.1685 s\n",
            "loss: 2.952 (epoch: 3, step: 300) // Avg time/img: 0.1686 s\n",
            "loss: 2.952 (epoch: 3, step: 350) // Avg time/img: 0.1687 s\n",
            "loss: 2.952 (epoch: 3, step: 400) // Avg time/img: 0.1686 s\n",
            "loss: 2.952 (epoch: 3, step: 450) // Avg time/img: 0.1687 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "2.94905948638916\n",
            "1\n",
            "VAL loss: 2.949 (epoch: 3, step: 0) // Avg time/img: 0.1784 s\n",
            "150.74833607673645\n",
            "51\n",
            "VAL loss: 2.956 (epoch: 3, step: 50) // Avg time/img: 0.1640 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m26.84\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 2.957 (epoch: 4, step: 0) // Avg time/img: 0.1912 s\n",
            "loss: 2.95 (epoch: 4, step: 50) // Avg time/img: 0.1697 s\n",
            "loss: 2.951 (epoch: 4, step: 100) // Avg time/img: 0.1691 s\n",
            "loss: 2.951 (epoch: 4, step: 150) // Avg time/img: 0.1690 s\n",
            "loss: 2.951 (epoch: 4, step: 200) // Avg time/img: 0.1689 s\n",
            "loss: 2.951 (epoch: 4, step: 250) // Avg time/img: 0.1689 s\n",
            "loss: 2.951 (epoch: 4, step: 300) // Avg time/img: 0.1688 s\n",
            "loss: 2.951 (epoch: 4, step: 350) // Avg time/img: 0.1687 s\n",
            "loss: 2.951 (epoch: 4, step: 400) // Avg time/img: 0.1686 s\n",
            "loss: 2.95 (epoch: 4, step: 450) // Avg time/img: 0.1686 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "2.9474852085113525\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 4, step: 0) // Avg time/img: 0.1822 s\n",
            "150.69450330734253\n",
            "51\n",
            "VAL loss: 2.955 (epoch: 4, step: 50) // Avg time/img: 0.1635 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m28.01\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 2.964 (epoch: 5, step: 0) // Avg time/img: 0.1858 s\n",
            "loss: 2.953 (epoch: 5, step: 50) // Avg time/img: 0.1699 s\n",
            "loss: 2.951 (epoch: 5, step: 100) // Avg time/img: 0.1693 s\n",
            "loss: 2.951 (epoch: 5, step: 150) // Avg time/img: 0.1692 s\n",
            "loss: 2.95 (epoch: 5, step: 200) // Avg time/img: 0.1689 s\n",
            "loss: 2.95 (epoch: 5, step: 250) // Avg time/img: 0.1688 s\n",
            "loss: 2.95 (epoch: 5, step: 300) // Avg time/img: 0.1687 s\n",
            "loss: 2.95 (epoch: 5, step: 350) // Avg time/img: 0.1687 s\n",
            "loss: 2.95 (epoch: 5, step: 400) // Avg time/img: 0.1686 s\n",
            "loss: 2.95 (epoch: 5, step: 450) // Avg time/img: 0.1685 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "2.9474000930786133\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 5, step: 0) // Avg time/img: 0.1794 s\n",
            "150.65880393981934\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 5, step: 50) // Avg time/img: 0.1633 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.12\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 2.949 (epoch: 6, step: 0) // Avg time/img: 0.1911 s\n",
            "loss: 2.951 (epoch: 6, step: 50) // Avg time/img: 0.1692 s\n",
            "loss: 2.95 (epoch: 6, step: 100) // Avg time/img: 0.1687 s\n",
            "loss: 2.95 (epoch: 6, step: 150) // Avg time/img: 0.1684 s\n",
            "loss: 2.95 (epoch: 6, step: 200) // Avg time/img: 0.1683 s\n",
            "loss: 2.95 (epoch: 6, step: 250) // Avg time/img: 0.1682 s\n",
            "loss: 2.949 (epoch: 6, step: 300) // Avg time/img: 0.1683 s\n",
            "loss: 2.949 (epoch: 6, step: 350) // Avg time/img: 0.1682 s\n",
            "loss: 2.949 (epoch: 6, step: 400) // Avg time/img: 0.1681 s\n",
            "loss: 2.949 (epoch: 6, step: 450) // Avg time/img: 0.1680 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "2.954045057296753\n",
            "1\n",
            "VAL loss: 2.954 (epoch: 6, step: 0) // Avg time/img: 0.1748 s\n",
            "150.63160467147827\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 6, step: 50) // Avg time/img: 0.1628 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.23\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 2.945 (epoch: 7, step: 0) // Avg time/img: 0.1783 s\n",
            "loss: 2.949 (epoch: 7, step: 50) // Avg time/img: 0.1700 s\n",
            "loss: 2.949 (epoch: 7, step: 100) // Avg time/img: 0.1693 s\n",
            "loss: 2.948 (epoch: 7, step: 150) // Avg time/img: 0.1688 s\n",
            "loss: 2.948 (epoch: 7, step: 200) // Avg time/img: 0.1685 s\n",
            "loss: 2.948 (epoch: 7, step: 250) // Avg time/img: 0.1685 s\n",
            "loss: 2.948 (epoch: 7, step: 300) // Avg time/img: 0.1684 s\n",
            "loss: 2.949 (epoch: 7, step: 350) // Avg time/img: 0.1683 s\n",
            "loss: 2.949 (epoch: 7, step: 400) // Avg time/img: 0.1682 s\n",
            "loss: 2.949 (epoch: 7, step: 450) // Avg time/img: 0.1682 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "2.949761390686035\n",
            "1\n",
            "VAL loss: 2.95 (epoch: 7, step: 0) // Avg time/img: 0.1775 s\n",
            "150.51734709739685\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 7, step: 50) // Avg time/img: 0.1628 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m32.20\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 2.944 (epoch: 8, step: 0) // Avg time/img: 0.1805 s\n",
            "loss: 2.948 (epoch: 8, step: 50) // Avg time/img: 0.1687 s\n",
            "loss: 2.948 (epoch: 8, step: 100) // Avg time/img: 0.1678 s\n",
            "loss: 2.948 (epoch: 8, step: 150) // Avg time/img: 0.1677 s\n",
            "loss: 2.948 (epoch: 8, step: 200) // Avg time/img: 0.1677 s\n",
            "loss: 2.948 (epoch: 8, step: 250) // Avg time/img: 0.1677 s\n",
            "loss: 2.948 (epoch: 8, step: 300) // Avg time/img: 0.1678 s\n",
            "loss: 2.948 (epoch: 8, step: 350) // Avg time/img: 0.1677 s\n",
            "loss: 2.948 (epoch: 8, step: 400) // Avg time/img: 0.1677 s\n",
            "loss: 2.948 (epoch: 8, step: 450) // Avg time/img: 0.1677 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "2.9466943740844727\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 8, step: 0) // Avg time/img: 0.1772 s\n",
            "150.51059246063232\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 8, step: 50) // Avg time/img: 0.1624 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m32.84\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 2.944 (epoch: 9, step: 0) // Avg time/img: 0.1860 s\n",
            "loss: 2.945 (epoch: 9, step: 50) // Avg time/img: 0.1682 s\n",
            "loss: 2.947 (epoch: 9, step: 100) // Avg time/img: 0.1676 s\n",
            "loss: 2.947 (epoch: 9, step: 150) // Avg time/img: 0.1677 s\n",
            "loss: 2.947 (epoch: 9, step: 200) // Avg time/img: 0.1677 s\n",
            "loss: 2.947 (epoch: 9, step: 250) // Avg time/img: 0.1676 s\n",
            "loss: 2.947 (epoch: 9, step: 300) // Avg time/img: 0.1676 s\n",
            "loss: 2.947 (epoch: 9, step: 350) // Avg time/img: 0.1676 s\n",
            "loss: 2.947 (epoch: 9, step: 400) // Avg time/img: 0.1676 s\n",
            "loss: 2.947 (epoch: 9, step: 450) // Avg time/img: 0.1676 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "2.9469962120056152\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 9, step: 0) // Avg time/img: 0.1784 s\n",
            "150.46468544006348\n",
            "51\n",
            "VAL loss: 2.95 (epoch: 9, step: 50) // Avg time/img: 0.1624 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.77\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_cross_entropy/model_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 2.949 (epoch: 10, step: 0) // Avg time/img: 0.1817 s\n",
            "loss: 2.947 (epoch: 10, step: 50) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 100) // Avg time/img: 0.1677 s\n",
            "loss: 2.947 (epoch: 10, step: 150) // Avg time/img: 0.1676 s\n",
            "loss: 2.946 (epoch: 10, step: 200) // Avg time/img: 0.1677 s\n",
            "loss: 2.946 (epoch: 10, step: 250) // Avg time/img: 0.1677 s\n",
            "loss: 2.946 (epoch: 10, step: 300) // Avg time/img: 0.1677 s\n",
            "loss: 2.947 (epoch: 10, step: 350) // Avg time/img: 0.1676 s\n",
            "loss: 2.946 (epoch: 10, step: 400) // Avg time/img: 0.1677 s\n",
            "loss: 2.946 (epoch: 10, step: 450) // Avg time/img: 0.1678 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "2.947218894958496\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 10, step: 0) // Avg time/img: 0.1791 s\n",
            "150.461186170578\n",
            "51\n",
            "VAL loss: 2.95 (epoch: 10, step: 50) // Avg time/img: 0.1631 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.35\u001b[0m %\n",
            "========== TRAINING FINISHED ===========\n"
          ]
        }
      ],
      "source": [
        "# Training with logit normalization loss with cross_entropy\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/train\n",
        "!python main.py  --savedir logit_norm_cross_entropy --datadir /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training --num-epochs 10 --batch-size 6 --lossfunction logit_norm --onlyone False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoa7ltl2ItD9",
        "outputId": "13ee07cb-1c45-4902-8959-f93c7516b8f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/train\n",
            "========== ENCODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "fine loader_val\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 2.998 (epoch: 1, step: 0) // Avg time/img: 0.7406 s\n",
            "loss: 2.986 (epoch: 1, step: 50) // Avg time/img: 0.1362 s\n",
            "loss: 2.981 (epoch: 1, step: 100) // Avg time/img: 0.1318 s\n",
            "loss: 2.978 (epoch: 1, step: 150) // Avg time/img: 0.1321 s\n",
            "loss: 2.977 (epoch: 1, step: 200) // Avg time/img: 0.1323 s\n",
            "loss: 2.976 (epoch: 1, step: 250) // Avg time/img: 0.1323 s\n",
            "loss: 2.975 (epoch: 1, step: 300) // Avg time/img: 0.1325 s\n",
            "loss: 2.973 (epoch: 1, step: 350) // Avg time/img: 0.1325 s\n",
            "loss: 2.973 (epoch: 1, step: 400) // Avg time/img: 0.1326 s\n",
            "loss: 2.972 (epoch: 1, step: 450) // Avg time/img: 0.1327 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:687: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:688: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  targets = Variable(labels, volatile=True)\n",
            "2.9649155139923096\n",
            "1\n",
            "VAL loss: 2.965 (epoch: 1, step: 0) // Avg time/img: 0.1499 s\n",
            "151.6650195121765\n",
            "51\n",
            "VAL loss: 2.974 (epoch: 1, step: 50) // Avg time/img: 0.1303 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m18.68\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 2.982 (epoch: 2, step: 0) // Avg time/img: 0.1445 s\n",
            "loss: 2.965 (epoch: 2, step: 50) // Avg time/img: 0.1337 s\n",
            "loss: 2.964 (epoch: 2, step: 100) // Avg time/img: 0.1331 s\n",
            "loss: 2.963 (epoch: 2, step: 150) // Avg time/img: 0.1328 s\n",
            "loss: 2.963 (epoch: 2, step: 200) // Avg time/img: 0.1328 s\n",
            "loss: 2.963 (epoch: 2, step: 250) // Avg time/img: 0.1328 s\n",
            "loss: 2.962 (epoch: 2, step: 300) // Avg time/img: 0.1328 s\n",
            "loss: 2.962 (epoch: 2, step: 350) // Avg time/img: 0.1327 s\n",
            "loss: 2.962 (epoch: 2, step: 400) // Avg time/img: 0.1327 s\n",
            "loss: 2.961 (epoch: 2, step: 450) // Avg time/img: 0.1328 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "2.949009418487549\n",
            "1\n",
            "VAL loss: 2.949 (epoch: 2, step: 0) // Avg time/img: 0.1405 s\n",
            "151.0411446094513\n",
            "51\n",
            "VAL loss: 2.962 (epoch: 2, step: 50) // Avg time/img: 0.1300 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m24.31\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 2.95 (epoch: 3, step: 0) // Avg time/img: 0.1476 s\n",
            "loss: 2.958 (epoch: 3, step: 50) // Avg time/img: 0.1335 s\n",
            "loss: 2.959 (epoch: 3, step: 100) // Avg time/img: 0.1332 s\n",
            "loss: 2.959 (epoch: 3, step: 150) // Avg time/img: 0.1329 s\n",
            "loss: 2.959 (epoch: 3, step: 200) // Avg time/img: 0.1328 s\n",
            "loss: 2.958 (epoch: 3, step: 250) // Avg time/img: 0.1327 s\n",
            "loss: 2.958 (epoch: 3, step: 300) // Avg time/img: 0.1326 s\n",
            "loss: 2.957 (epoch: 3, step: 350) // Avg time/img: 0.1325 s\n",
            "loss: 2.957 (epoch: 3, step: 400) // Avg time/img: 0.1324 s\n",
            "loss: 2.957 (epoch: 3, step: 450) // Avg time/img: 0.1324 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "2.947316884994507\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 3, step: 0) // Avg time/img: 0.1435 s\n",
            "151.02016639709473\n",
            "51\n",
            "VAL loss: 2.961 (epoch: 3, step: 50) // Avg time/img: 0.1297 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m24.35\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 2.977 (epoch: 4, step: 0) // Avg time/img: 0.1477 s\n",
            "loss: 2.955 (epoch: 4, step: 50) // Avg time/img: 0.1334 s\n",
            "loss: 2.955 (epoch: 4, step: 100) // Avg time/img: 0.1329 s\n",
            "loss: 2.955 (epoch: 4, step: 150) // Avg time/img: 0.1326 s\n",
            "loss: 2.954 (epoch: 4, step: 200) // Avg time/img: 0.1324 s\n",
            "loss: 2.954 (epoch: 4, step: 250) // Avg time/img: 0.1324 s\n",
            "loss: 2.954 (epoch: 4, step: 300) // Avg time/img: 0.1323 s\n",
            "loss: 2.954 (epoch: 4, step: 350) // Avg time/img: 0.1323 s\n",
            "loss: 2.954 (epoch: 4, step: 400) // Avg time/img: 0.1323 s\n",
            "loss: 2.954 (epoch: 4, step: 450) // Avg time/img: 0.1322 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "2.945509672164917\n",
            "1\n",
            "VAL loss: 2.946 (epoch: 4, step: 0) // Avg time/img: 0.1465 s\n",
            "150.79903936386108\n",
            "51\n",
            "VAL loss: 2.957 (epoch: 4, step: 50) // Avg time/img: 0.1295 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m28.11\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 2.966 (epoch: 5, step: 0) // Avg time/img: 0.1415 s\n",
            "loss: 2.951 (epoch: 5, step: 50) // Avg time/img: 0.1324 s\n",
            "loss: 2.951 (epoch: 5, step: 100) // Avg time/img: 0.1321 s\n",
            "loss: 2.951 (epoch: 5, step: 150) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 200) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 250) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 300) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 350) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 400) // Avg time/img: 0.1318 s\n",
            "loss: 2.951 (epoch: 5, step: 450) // Avg time/img: 0.1318 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "2.9449634552001953\n",
            "1\n",
            "VAL loss: 2.945 (epoch: 5, step: 0) // Avg time/img: 0.1428 s\n",
            "150.63122582435608\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 5, step: 50) // Avg time/img: 0.1293 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m32.11\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 2.945 (epoch: 6, step: 0) // Avg time/img: 0.1467 s\n",
            "loss: 2.948 (epoch: 6, step: 50) // Avg time/img: 0.1328 s\n",
            "loss: 2.948 (epoch: 6, step: 100) // Avg time/img: 0.1321 s\n",
            "loss: 2.949 (epoch: 6, step: 150) // Avg time/img: 0.1319 s\n",
            "loss: 2.949 (epoch: 6, step: 200) // Avg time/img: 0.1319 s\n",
            "loss: 2.949 (epoch: 6, step: 250) // Avg time/img: 0.1318 s\n",
            "loss: 2.949 (epoch: 6, step: 300) // Avg time/img: 0.1317 s\n",
            "loss: 2.949 (epoch: 6, step: 350) // Avg time/img: 0.1318 s\n",
            "loss: 2.949 (epoch: 6, step: 400) // Avg time/img: 0.1318 s\n",
            "loss: 2.949 (epoch: 6, step: 450) // Avg time/img: 0.1318 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "2.9444987773895264\n",
            "1\n",
            "VAL loss: 2.944 (epoch: 6, step: 0) // Avg time/img: 0.1399 s\n",
            "150.60005068778992\n",
            "51\n",
            "VAL loss: 2.953 (epoch: 6, step: 50) // Avg time/img: 0.1293 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.71\u001b[0m %\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 2.946 (epoch: 7, step: 0) // Avg time/img: 0.1477 s\n",
            "loss: 2.948 (epoch: 7, step: 50) // Avg time/img: 0.1327 s\n",
            "loss: 2.948 (epoch: 7, step: 100) // Avg time/img: 0.1321 s\n",
            "loss: 2.948 (epoch: 7, step: 150) // Avg time/img: 0.1318 s\n",
            "loss: 2.948 (epoch: 7, step: 200) // Avg time/img: 0.1317 s\n",
            "loss: 2.947 (epoch: 7, step: 250) // Avg time/img: 0.1317 s\n",
            "loss: 2.947 (epoch: 7, step: 300) // Avg time/img: 0.1316 s\n",
            "loss: 2.947 (epoch: 7, step: 350) // Avg time/img: 0.1316 s\n",
            "loss: 2.947 (epoch: 7, step: 400) // Avg time/img: 0.1316 s\n",
            "loss: 2.947 (epoch: 7, step: 450) // Avg time/img: 0.1316 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "2.944429397583008\n",
            "1\n",
            "VAL loss: 2.944 (epoch: 7, step: 0) // Avg time/img: 0.1398 s\n",
            "150.52553415298462\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 7, step: 50) // Avg time/img: 0.1289 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.40\u001b[0m %\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 2.941 (epoch: 8, step: 0) // Avg time/img: 0.1450 s\n",
            "loss: 2.946 (epoch: 8, step: 50) // Avg time/img: 0.1327 s\n",
            "loss: 2.946 (epoch: 8, step: 100) // Avg time/img: 0.1320 s\n",
            "loss: 2.946 (epoch: 8, step: 150) // Avg time/img: 0.1324 s\n",
            "loss: 2.946 (epoch: 8, step: 200) // Avg time/img: 0.1323 s\n",
            "loss: 2.946 (epoch: 8, step: 250) // Avg time/img: 0.1322 s\n",
            "loss: 2.946 (epoch: 8, step: 300) // Avg time/img: 0.1321 s\n",
            "loss: 2.945 (epoch: 8, step: 350) // Avg time/img: 0.1321 s\n",
            "loss: 2.945 (epoch: 8, step: 400) // Avg time/img: 0.1321 s\n",
            "loss: 2.945 (epoch: 8, step: 450) // Avg time/img: 0.1322 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "2.9438891410827637\n",
            "1\n",
            "VAL loss: 2.944 (epoch: 8, step: 0) // Avg time/img: 0.1434 s\n",
            "150.32884192466736\n",
            "51\n",
            "VAL loss: 2.948 (epoch: 8, step: 50) // Avg time/img: 0.1304 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m34.75\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 2.952 (epoch: 9, step: 0) // Avg time/img: 0.1467 s\n",
            "loss: 2.943 (epoch: 9, step: 50) // Avg time/img: 0.1331 s\n",
            "loss: 2.943 (epoch: 9, step: 100) // Avg time/img: 0.1325 s\n",
            "loss: 2.943 (epoch: 9, step: 150) // Avg time/img: 0.1325 s\n",
            "loss: 2.943 (epoch: 9, step: 200) // Avg time/img: 0.1323 s\n",
            "loss: 2.943 (epoch: 9, step: 250) // Avg time/img: 0.1322 s\n",
            "loss: 2.943 (epoch: 9, step: 300) // Avg time/img: 0.1321 s\n",
            "loss: 2.943 (epoch: 9, step: 350) // Avg time/img: 0.1320 s\n",
            "loss: 2.943 (epoch: 9, step: 400) // Avg time/img: 0.1319 s\n",
            "loss: 2.944 (epoch: 9, step: 450) // Avg time/img: 0.1319 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "2.9430713653564453\n",
            "1\n",
            "VAL loss: 2.943 (epoch: 9, step: 0) // Avg time/img: 0.1388 s\n",
            "150.33332467079163\n",
            "51\n",
            "VAL loss: 2.948 (epoch: 9, step: 50) // Avg time/img: 0.1290 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.95\u001b[0m %\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 2.942 (epoch: 10, step: 0) // Avg time/img: 0.1411 s\n",
            "loss: 2.943 (epoch: 10, step: 50) // Avg time/img: 0.1321 s\n",
            "loss: 2.942 (epoch: 10, step: 100) // Avg time/img: 0.1319 s\n",
            "loss: 2.943 (epoch: 10, step: 150) // Avg time/img: 0.1317 s\n",
            "loss: 2.942 (epoch: 10, step: 200) // Avg time/img: 0.1315 s\n",
            "loss: 2.942 (epoch: 10, step: 250) // Avg time/img: 0.1315 s\n",
            "loss: 2.942 (epoch: 10, step: 300) // Avg time/img: 0.1314 s\n",
            "loss: 2.942 (epoch: 10, step: 350) // Avg time/img: 0.1314 s\n",
            "loss: 2.942 (epoch: 10, step: 400) // Avg time/img: 0.1314 s\n",
            "loss: 2.942 (epoch: 10, step: 450) // Avg time/img: 0.1314 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "2.942077875137329\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 10, step: 0) // Avg time/img: 0.1418 s\n",
            "150.24060487747192\n",
            "51\n",
            "VAL loss: 2.946 (epoch: 10, step: 50) // Avg time/img: 0.1291 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m35.56\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_encoder_best.pth (epoch: 10)\n",
            "========== DECODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "fine loader_val\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 2.995 (epoch: 1, step: 0) // Avg time/img: 0.1897 s\n",
            "loss: 2.992 (epoch: 1, step: 50) // Avg time/img: 0.1748 s\n",
            "loss: 2.988 (epoch: 1, step: 100) // Avg time/img: 0.1740 s\n",
            "loss: 2.984 (epoch: 1, step: 150) // Avg time/img: 0.1734 s\n",
            "loss: 2.982 (epoch: 1, step: 200) // Avg time/img: 0.1731 s\n",
            "loss: 2.98 (epoch: 1, step: 250) // Avg time/img: 0.1728 s\n",
            "loss: 2.978 (epoch: 1, step: 300) // Avg time/img: 0.1726 s\n",
            "loss: 2.977 (epoch: 1, step: 350) // Avg time/img: 0.1725 s\n",
            "loss: 2.975 (epoch: 1, step: 400) // Avg time/img: 0.1723 s\n",
            "loss: 2.974 (epoch: 1, step: 450) // Avg time/img: 0.1722 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "2.956552028656006\n",
            "1\n",
            "VAL loss: 2.957 (epoch: 1, step: 0) // Avg time/img: 0.1857 s\n",
            "151.3728141784668\n",
            "51\n",
            "VAL loss: 2.968 (epoch: 1, step: 50) // Avg time/img: 0.1666 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m22.48\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 2.959 (epoch: 2, step: 0) // Avg time/img: 0.1842 s\n",
            "loss: 2.961 (epoch: 2, step: 50) // Avg time/img: 0.1731 s\n",
            "loss: 2.962 (epoch: 2, step: 100) // Avg time/img: 0.1723 s\n",
            "loss: 2.961 (epoch: 2, step: 150) // Avg time/img: 0.1719 s\n",
            "loss: 2.961 (epoch: 2, step: 200) // Avg time/img: 0.1717 s\n",
            "loss: 2.96 (epoch: 2, step: 250) // Avg time/img: 0.1716 s\n",
            "loss: 2.96 (epoch: 2, step: 300) // Avg time/img: 0.1715 s\n",
            "loss: 2.96 (epoch: 2, step: 350) // Avg time/img: 0.1713 s\n",
            "loss: 2.96 (epoch: 2, step: 400) // Avg time/img: 0.1713 s\n",
            "loss: 2.959 (epoch: 2, step: 450) // Avg time/img: 0.1713 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "2.948430299758911\n",
            "1\n",
            "VAL loss: 2.948 (epoch: 2, step: 0) // Avg time/img: 0.1799 s\n",
            "151.07938289642334\n",
            "51\n",
            "VAL loss: 2.962 (epoch: 2, step: 50) // Avg time/img: 0.1664 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m27.46\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 2.952 (epoch: 3, step: 0) // Avg time/img: 0.1858 s\n",
            "loss: 2.957 (epoch: 3, step: 50) // Avg time/img: 0.1721 s\n",
            "loss: 2.956 (epoch: 3, step: 100) // Avg time/img: 0.1715 s\n",
            "loss: 2.956 (epoch: 3, step: 150) // Avg time/img: 0.1710 s\n",
            "loss: 2.956 (epoch: 3, step: 200) // Avg time/img: 0.1708 s\n",
            "loss: 2.956 (epoch: 3, step: 250) // Avg time/img: 0.1707 s\n",
            "loss: 2.956 (epoch: 3, step: 300) // Avg time/img: 0.1706 s\n",
            "loss: 2.956 (epoch: 3, step: 350) // Avg time/img: 0.1706 s\n",
            "loss: 2.956 (epoch: 3, step: 400) // Avg time/img: 0.1705 s\n",
            "loss: 2.956 (epoch: 3, step: 450) // Avg time/img: 0.1705 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "2.9469358921051025\n",
            "1\n",
            "VAL loss: 2.947 (epoch: 3, step: 0) // Avg time/img: 0.1802 s\n",
            "150.9778401851654\n",
            "51\n",
            "VAL loss: 2.96 (epoch: 3, step: 50) // Avg time/img: 0.1657 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m27.34\u001b[0m %\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 2.963 (epoch: 4, step: 0) // Avg time/img: 0.1851 s\n",
            "loss: 2.955 (epoch: 4, step: 50) // Avg time/img: 0.1711 s\n",
            "loss: 2.954 (epoch: 4, step: 100) // Avg time/img: 0.1705 s\n",
            "loss: 2.954 (epoch: 4, step: 150) // Avg time/img: 0.1703 s\n",
            "loss: 2.954 (epoch: 4, step: 200) // Avg time/img: 0.1704 s\n",
            "loss: 2.954 (epoch: 4, step: 250) // Avg time/img: 0.1704 s\n",
            "loss: 2.954 (epoch: 4, step: 300) // Avg time/img: 0.1702 s\n",
            "loss: 2.954 (epoch: 4, step: 350) // Avg time/img: 0.1701 s\n",
            "loss: 2.954 (epoch: 4, step: 400) // Avg time/img: 0.1700 s\n",
            "loss: 2.955 (epoch: 4, step: 450) // Avg time/img: 0.1699 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "2.9462625980377197\n",
            "1\n",
            "VAL loss: 2.946 (epoch: 4, step: 0) // Avg time/img: 0.1855 s\n",
            "150.91787385940552\n",
            "51\n",
            "VAL loss: 2.959 (epoch: 4, step: 50) // Avg time/img: 0.1656 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m27.87\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 2.972 (epoch: 5, step: 0) // Avg time/img: 0.1886 s\n",
            "loss: 2.952 (epoch: 5, step: 50) // Avg time/img: 0.1720 s\n",
            "loss: 2.953 (epoch: 5, step: 100) // Avg time/img: 0.1705 s\n",
            "loss: 2.953 (epoch: 5, step: 150) // Avg time/img: 0.1703 s\n",
            "loss: 2.953 (epoch: 5, step: 200) // Avg time/img: 0.1700 s\n",
            "loss: 2.953 (epoch: 5, step: 250) // Avg time/img: 0.1698 s\n",
            "loss: 2.953 (epoch: 5, step: 300) // Avg time/img: 0.1698 s\n",
            "loss: 2.953 (epoch: 5, step: 350) // Avg time/img: 0.1696 s\n",
            "loss: 2.953 (epoch: 5, step: 400) // Avg time/img: 0.1696 s\n",
            "loss: 2.953 (epoch: 5, step: 450) // Avg time/img: 0.1696 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "2.946302652359009\n",
            "1\n",
            "VAL loss: 2.946 (epoch: 5, step: 0) // Avg time/img: 0.1792 s\n",
            "150.85345935821533\n",
            "51\n",
            "VAL loss: 2.958 (epoch: 5, step: 50) // Avg time/img: 0.1651 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.06\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 2.949 (epoch: 6, step: 0) // Avg time/img: 0.1844 s\n",
            "loss: 2.952 (epoch: 6, step: 50) // Avg time/img: 0.1709 s\n",
            "loss: 2.952 (epoch: 6, step: 100) // Avg time/img: 0.1699 s\n",
            "loss: 2.952 (epoch: 6, step: 150) // Avg time/img: 0.1696 s\n",
            "loss: 2.952 (epoch: 6, step: 200) // Avg time/img: 0.1696 s\n",
            "loss: 2.952 (epoch: 6, step: 250) // Avg time/img: 0.1695 s\n",
            "loss: 2.952 (epoch: 6, step: 300) // Avg time/img: 0.1694 s\n",
            "loss: 2.951 (epoch: 6, step: 350) // Avg time/img: 0.1693 s\n",
            "loss: 2.952 (epoch: 6, step: 400) // Avg time/img: 0.1692 s\n",
            "loss: 2.952 (epoch: 6, step: 450) // Avg time/img: 0.1692 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "2.9447085857391357\n",
            "1\n",
            "VAL loss: 2.945 (epoch: 6, step: 0) // Avg time/img: 0.1769 s\n",
            "150.7384638786316\n",
            "51\n",
            "VAL loss: 2.956 (epoch: 6, step: 50) // Avg time/img: 0.1643 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.57\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm_with_focal_loss/model_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 2.942 (epoch: 7, step: 0) // Avg time/img: 0.1810 s\n",
            "loss: 2.95 (epoch: 7, step: 50) // Avg time/img: 0.1705 s\n",
            "loss: 2.951 (epoch: 7, step: 100) // Avg time/img: 0.1695 s\n",
            "loss: 2.951 (epoch: 7, step: 150) // Avg time/img: 0.1692 s\n",
            "loss: 2.951 (epoch: 7, step: 200) // Avg time/img: 0.1691 s\n",
            "loss: 2.95 (epoch: 7, step: 250) // Avg time/img: 0.1690 s\n",
            "loss: 2.95 (epoch: 7, step: 300) // Avg time/img: 0.1690 s\n",
            "loss: 2.951 (epoch: 7, step: 350) // Avg time/img: 0.1689 s\n",
            "loss: 2.95 (epoch: 7, step: 400) // Avg time/img: 0.1689 s\n",
            "loss: 2.95 (epoch: 7, step: 450) // Avg time/img: 0.1688 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "2.9508066177368164\n",
            "1\n",
            "VAL loss: 2.951 (epoch: 7, step: 0) // Avg time/img: 0.1807 s\n",
            "150.6583468914032\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 7, step: 50) // Avg time/img: 0.1642 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m32.76\u001b[0m %\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 2.946 (epoch: 8, step: 0) // Avg time/img: 0.1814 s\n",
            "loss: 2.949 (epoch: 8, step: 50) // Avg time/img: 0.1698 s\n",
            "loss: 2.949 (epoch: 8, step: 100) // Avg time/img: 0.1692 s\n",
            "loss: 2.949 (epoch: 8, step: 150) // Avg time/img: 0.1691 s\n",
            "loss: 2.948 (epoch: 8, step: 200) // Avg time/img: 0.1689 s\n",
            "loss: 2.948 (epoch: 8, step: 250) // Avg time/img: 0.1687 s\n",
            "loss: 2.948 (epoch: 8, step: 300) // Avg time/img: 0.1686 s\n",
            "loss: 2.948 (epoch: 8, step: 350) // Avg time/img: 0.1686 s\n",
            "loss: 2.948 (epoch: 8, step: 400) // Avg time/img: 0.1684 s\n",
            "loss: 2.948 (epoch: 8, step: 450) // Avg time/img: 0.1684 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "2.9491569995880127\n",
            "1\n",
            "VAL loss: 2.949 (epoch: 8, step: 0) // Avg time/img: 0.1817 s\n",
            "150.65962862968445\n",
            "51\n",
            "VAL loss: 2.954 (epoch: 8, step: 50) // Avg time/img: 0.1639 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.07\u001b[0m %\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 2.943 (epoch: 9, step: 0) // Avg time/img: 0.1882 s\n",
            "loss: 2.947 (epoch: 9, step: 50) // Avg time/img: 0.1701 s\n",
            "loss: 2.947 (epoch: 9, step: 100) // Avg time/img: 0.1690 s\n",
            "loss: 2.947 (epoch: 9, step: 150) // Avg time/img: 0.1687 s\n",
            "loss: 2.947 (epoch: 9, step: 200) // Avg time/img: 0.1686 s\n",
            "loss: 2.947 (epoch: 9, step: 250) // Avg time/img: 0.1685 s\n",
            "loss: 2.947 (epoch: 9, step: 300) // Avg time/img: 0.1684 s\n",
            "loss: 2.947 (epoch: 9, step: 350) // Avg time/img: 0.1683 s\n",
            "loss: 2.947 (epoch: 9, step: 400) // Avg time/img: 0.1683 s\n",
            "loss: 2.947 (epoch: 9, step: 450) // Avg time/img: 0.1683 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "2.949126958847046\n",
            "1\n",
            "VAL loss: 2.949 (epoch: 9, step: 0) // Avg time/img: 0.1788 s\n",
            "150.52280688285828\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 9, step: 50) // Avg time/img: 0.1637 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.56\u001b[0m %\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 2.951 (epoch: 10, step: 0) // Avg time/img: 0.1814 s\n",
            "loss: 2.945 (epoch: 10, step: 50) // Avg time/img: 0.1691 s\n",
            "loss: 2.946 (epoch: 10, step: 100) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 150) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 200) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 250) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 300) // Avg time/img: 0.1685 s\n",
            "loss: 2.946 (epoch: 10, step: 350) // Avg time/img: 0.1684 s\n",
            "loss: 2.946 (epoch: 10, step: 400) // Avg time/img: 0.1684 s\n",
            "loss: 2.946 (epoch: 10, step: 450) // Avg time/img: 0.1683 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "2.9485394954681396\n",
            "1\n",
            "VAL loss: 2.949 (epoch: 10, step: 0) // Avg time/img: 0.1812 s\n",
            "150.4329650402069\n",
            "51\n",
            "VAL loss: 2.95 (epoch: 10, step: 50) // Avg time/img: 0.1639 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.52\u001b[0m %\n",
            "========== TRAINING FINISHED ===========\n"
          ]
        }
      ],
      "source": [
        "# Training with logit normalization loss with focal loss\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/train\n",
        "!python main.py  --savedir logit_norm_with_focal_loss --datadir /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training --num-epochs 10 --batch-size 6 --lossfunction logit_norm --onlyone False --focal_loss True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJGeGj2eSCyt",
        "outputId": "7b3ab092-3aee-46cc-ba62-901901b1484f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/train\n",
            "========== ENCODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:248: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  weight = torch.tensor(weights)\n",
            "calcolo loader\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "fine loader_val\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:222: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
            "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "=> Loaded checkpoint at epoch 11)\n",
            "========== DECODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "fine loader_val\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "=> Loaded checkpoint at epoch 4)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 2.969 (epoch: 4, step: 0) // Avg time/img: 0.9171 s\n",
            "loss: 2.95 (epoch: 4, step: 50) // Avg time/img: 0.1829 s\n",
            "loss: 2.95 (epoch: 4, step: 100) // Avg time/img: 0.1757 s\n",
            "loss: 2.95 (epoch: 4, step: 150) // Avg time/img: 0.1734 s\n",
            "loss: 2.95 (epoch: 4, step: 200) // Avg time/img: 0.1722 s\n",
            "loss: 2.95 (epoch: 4, step: 250) // Avg time/img: 0.1716 s\n",
            "loss: 2.95 (epoch: 4, step: 300) // Avg time/img: 0.1711 s\n",
            "loss: 2.95 (epoch: 4, step: 350) // Avg time/img: 0.1707 s\n",
            "loss: 2.95 (epoch: 4, step: 400) // Avg time/img: 0.1704 s\n",
            "loss: 2.95 (epoch: 4, step: 450) // Avg time/img: 0.1703 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:460: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:461: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  targets = Variable(labels, volatile=True)\n",
            "2.94648814201355\n",
            "1\n",
            "VAL loss: 2.946 (epoch: 4, step: 0) // Avg time/img: 0.1809 s\n",
            "150.62633323669434\n",
            "51\n",
            "VAL loss: 2.953 (epoch: 4, step: 50) // Avg time/img: 0.1634 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m29.72\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 2.952 (epoch: 5, step: 0) // Avg time/img: 0.1832 s\n",
            "loss: 2.948 (epoch: 5, step: 50) // Avg time/img: 0.1696 s\n",
            "loss: 2.949 (epoch: 5, step: 100) // Avg time/img: 0.1690 s\n",
            "loss: 2.949 (epoch: 5, step: 150) // Avg time/img: 0.1688 s\n",
            "loss: 2.949 (epoch: 5, step: 200) // Avg time/img: 0.1687 s\n",
            "loss: 2.948 (epoch: 5, step: 250) // Avg time/img: 0.1687 s\n",
            "loss: 2.948 (epoch: 5, step: 300) // Avg time/img: 0.1686 s\n",
            "loss: 2.948 (epoch: 5, step: 350) // Avg time/img: 0.1686 s\n",
            "loss: 2.948 (epoch: 5, step: 400) // Avg time/img: 0.1687 s\n",
            "loss: 2.948 (epoch: 5, step: 450) // Avg time/img: 0.1688 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "2.942610263824463\n",
            "1\n",
            "VAL loss: 2.943 (epoch: 5, step: 0) // Avg time/img: 0.1814 s\n",
            "150.57931780815125\n",
            "51\n",
            "VAL loss: 2.953 (epoch: 5, step: 50) // Avg time/img: 0.1634 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.08\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 2.942 (epoch: 6, step: 0) // Avg time/img: 0.1882 s\n",
            "loss: 2.948 (epoch: 6, step: 50) // Avg time/img: 0.1696 s\n",
            "loss: 2.948 (epoch: 6, step: 100) // Avg time/img: 0.1692 s\n",
            "loss: 2.948 (epoch: 6, step: 150) // Avg time/img: 0.1691 s\n",
            "loss: 2.948 (epoch: 6, step: 200) // Avg time/img: 0.1691 s\n",
            "loss: 2.948 (epoch: 6, step: 250) // Avg time/img: 0.1690 s\n",
            "loss: 2.948 (epoch: 6, step: 300) // Avg time/img: 0.1690 s\n",
            "loss: 2.948 (epoch: 6, step: 350) // Avg time/img: 0.1690 s\n",
            "loss: 2.948 (epoch: 6, step: 400) // Avg time/img: 0.1690 s\n",
            "loss: 2.948 (epoch: 6, step: 450) // Avg time/img: 0.1689 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "2.9426727294921875\n",
            "1\n",
            "VAL loss: 2.943 (epoch: 6, step: 0) // Avg time/img: 0.1782 s\n",
            "150.4887239933014\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 6, step: 50) // Avg time/img: 0.1631 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.34\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 2.943 (epoch: 7, step: 0) // Avg time/img: 0.1902 s\n",
            "loss: 2.946 (epoch: 7, step: 50) // Avg time/img: 0.1695 s\n",
            "loss: 2.947 (epoch: 7, step: 100) // Avg time/img: 0.1690 s\n",
            "loss: 2.947 (epoch: 7, step: 150) // Avg time/img: 0.1689 s\n",
            "loss: 2.947 (epoch: 7, step: 200) // Avg time/img: 0.1688 s\n",
            "loss: 2.947 (epoch: 7, step: 250) // Avg time/img: 0.1688 s\n",
            "loss: 2.947 (epoch: 7, step: 300) // Avg time/img: 0.1687 s\n",
            "loss: 2.947 (epoch: 7, step: 350) // Avg time/img: 0.1688 s\n",
            "loss: 2.947 (epoch: 7, step: 400) // Avg time/img: 0.1688 s\n",
            "loss: 2.947 (epoch: 7, step: 450) // Avg time/img: 0.1687 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "2.9422590732574463\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 7, step: 0) // Avg time/img: 0.1818 s\n",
            "150.45820498466492\n",
            "51\n",
            "VAL loss: 2.95 (epoch: 7, step: 50) // Avg time/img: 0.1630 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m32.08\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 2.942 (epoch: 8, step: 0) // Avg time/img: 0.1832 s\n",
            "loss: 2.946 (epoch: 8, step: 50) // Avg time/img: 0.1686 s\n",
            "loss: 2.946 (epoch: 8, step: 100) // Avg time/img: 0.1682 s\n",
            "loss: 2.946 (epoch: 8, step: 150) // Avg time/img: 0.1682 s\n",
            "loss: 2.946 (epoch: 8, step: 200) // Avg time/img: 0.1682 s\n",
            "loss: 2.945 (epoch: 8, step: 250) // Avg time/img: 0.1681 s\n",
            "loss: 2.946 (epoch: 8, step: 300) // Avg time/img: 0.1680 s\n",
            "loss: 2.946 (epoch: 8, step: 350) // Avg time/img: 0.1679 s\n",
            "loss: 2.946 (epoch: 8, step: 400) // Avg time/img: 0.1679 s\n",
            "loss: 2.946 (epoch: 8, step: 450) // Avg time/img: 0.1678 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "2.9433436393737793\n",
            "1\n",
            "VAL loss: 2.943 (epoch: 8, step: 0) // Avg time/img: 0.1792 s\n",
            "150.5123155117035\n",
            "51\n",
            "VAL loss: 2.951 (epoch: 8, step: 50) // Avg time/img: 0.1625 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.17\u001b[0m %\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 2.947 (epoch: 9, step: 0) // Avg time/img: 0.1847 s\n",
            "loss: 2.946 (epoch: 9, step: 50) // Avg time/img: 0.1689 s\n",
            "loss: 2.945 (epoch: 9, step: 100) // Avg time/img: 0.1683 s\n",
            "loss: 2.945 (epoch: 9, step: 150) // Avg time/img: 0.1682 s\n",
            "loss: 2.945 (epoch: 9, step: 200) // Avg time/img: 0.1681 s\n",
            "loss: 2.945 (epoch: 9, step: 250) // Avg time/img: 0.1681 s\n",
            "loss: 2.945 (epoch: 9, step: 300) // Avg time/img: 0.1680 s\n",
            "loss: 2.945 (epoch: 9, step: 350) // Avg time/img: 0.1678 s\n",
            "loss: 2.945 (epoch: 9, step: 400) // Avg time/img: 0.1678 s\n",
            "loss: 2.945 (epoch: 9, step: 450) // Avg time/img: 0.1678 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "2.9417543411254883\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 9, step: 0) // Avg time/img: 0.1770 s\n",
            "150.38718938827515\n",
            "51\n",
            "VAL loss: 2.949 (epoch: 9, step: 50) // Avg time/img: 0.1623 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.71\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 2.941 (epoch: 10, step: 0) // Avg time/img: 0.1776 s\n",
            "loss: 2.945 (epoch: 10, step: 50) // Avg time/img: 0.1692 s\n",
            "loss: 2.945 (epoch: 10, step: 100) // Avg time/img: 0.1682 s\n",
            "loss: 2.945 (epoch: 10, step: 150) // Avg time/img: 0.1679 s\n",
            "loss: 2.945 (epoch: 10, step: 200) // Avg time/img: 0.1677 s\n",
            "loss: 2.945 (epoch: 10, step: 250) // Avg time/img: 0.1676 s\n",
            "loss: 2.945 (epoch: 10, step: 300) // Avg time/img: 0.1675 s\n",
            "loss: 2.945 (epoch: 10, step: 350) // Avg time/img: 0.1673 s\n",
            "loss: 2.944 (epoch: 10, step: 400) // Avg time/img: 0.1673 s\n",
            "loss: 2.944 (epoch: 10, step: 450) // Avg time/img: 0.1673 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "2.9415130615234375\n",
            "1\n",
            "VAL loss: 2.942 (epoch: 10, step: 0) // Avg time/img: 0.1792 s\n",
            "150.36000084877014\n",
            "51\n",
            "VAL loss: 2.948 (epoch: 10, step: 50) // Avg time/img: 0.1623 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m33.71\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/logit_norm/model_best.pth (epoch: 10)\n",
            "========== TRAINING FINISHED ===========\n"
          ]
        }
      ],
      "source": [
        "# Training with logit normalization loss\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/train\n",
        "!python main.py  --resume --savedir logit_norm --datadir /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training --num-epochs 10 --batch-size 6 --lossfunction logit_norm --onlyone True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HjLDRo2ysa-",
        "outputId": "b5f5eddd-b3d0-4cfc-83a0-f0bb941fe755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AnomalySegmentation_CourseProjectBaseCode/train\n",
            "========== ENCODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "fine loader_val\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.class_weights = torch.tensor(class_weights)\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 251.7 (epoch: 1, step: 0) // Avg time/img: 0.7743 s\n",
            "loss: 212.6 (epoch: 1, step: 50) // Avg time/img: 0.1380 s\n",
            "loss: 207.4 (epoch: 1, step: 100) // Avg time/img: 0.1336 s\n",
            "loss: 203.1 (epoch: 1, step: 150) // Avg time/img: 0.1338 s\n",
            "loss: 200.8 (epoch: 1, step: 200) // Avg time/img: 0.1339 s\n",
            "loss: 197.3 (epoch: 1, step: 250) // Avg time/img: 0.1338 s\n",
            "loss: 196.9 (epoch: 1, step: 300) // Avg time/img: 0.1338 s\n",
            "loss: 196.9 (epoch: 1, step: 350) // Avg time/img: 0.1337 s\n",
            "loss: 197.1 (epoch: 1, step: 400) // Avg time/img: 0.1337 s\n",
            "loss: 196.8 (epoch: 1, step: 450) // Avg time/img: 0.1337 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:687: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/train/main.py:688: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  targets = Variable(labels, volatile=True)\n",
            "164.57907104492188\n",
            "1\n",
            "VAL loss: 164.6 (epoch: 1, step: 0) // Avg time/img: 0.1619 s\n",
            "9839.011848449707\n",
            "51\n",
            "VAL loss: 192.9 (epoch: 1, step: 50) // Avg time/img: 0.1312 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m11.71\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 217.2 (epoch: 2, step: 0) // Avg time/img: 0.1478 s\n",
            "loss: 199.2 (epoch: 2, step: 50) // Avg time/img: 0.1352 s\n",
            "loss: 196.9 (epoch: 2, step: 100) // Avg time/img: 0.1343 s\n",
            "loss: 196.5 (epoch: 2, step: 150) // Avg time/img: 0.1341 s\n",
            "loss: 196.4 (epoch: 2, step: 200) // Avg time/img: 0.1339 s\n",
            "loss: 194.8 (epoch: 2, step: 250) // Avg time/img: 0.1338 s\n",
            "loss: 195.9 (epoch: 2, step: 300) // Avg time/img: 0.1337 s\n",
            "loss: 195.4 (epoch: 2, step: 350) // Avg time/img: 0.1338 s\n",
            "loss: 195.2 (epoch: 2, step: 400) // Avg time/img: 0.1337 s\n",
            "loss: 195.0 (epoch: 2, step: 450) // Avg time/img: 0.1336 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "167.03338623046875\n",
            "1\n",
            "VAL loss: 167.0 (epoch: 2, step: 0) // Avg time/img: 0.1408 s\n",
            "9959.932174682617\n",
            "51\n",
            "VAL loss: 195.3 (epoch: 2, step: 50) // Avg time/img: 0.1308 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m6.43\u001b[0m %\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 243.2 (epoch: 3, step: 0) // Avg time/img: 0.1446 s\n",
            "loss: 202.1 (epoch: 3, step: 50) // Avg time/img: 0.1344 s\n",
            "loss: 196.9 (epoch: 3, step: 100) // Avg time/img: 0.1337 s\n",
            "loss: 197.0 (epoch: 3, step: 150) // Avg time/img: 0.1336 s\n",
            "loss: 196.1 (epoch: 3, step: 200) // Avg time/img: 0.1335 s\n",
            "loss: 196.9 (epoch: 3, step: 250) // Avg time/img: 0.1334 s\n",
            "loss: 196.6 (epoch: 3, step: 300) // Avg time/img: 0.1333 s\n",
            "loss: 196.8 (epoch: 3, step: 350) // Avg time/img: 0.1333 s\n",
            "loss: 196.6 (epoch: 3, step: 400) // Avg time/img: 0.1333 s\n",
            "loss: 196.0 (epoch: 3, step: 450) // Avg time/img: 0.1332 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "162.44357299804688\n",
            "1\n",
            "VAL loss: 162.4 (epoch: 3, step: 0) // Avg time/img: 0.1450 s\n",
            "9749.79084777832\n",
            "51\n",
            "VAL loss: 191.2 (epoch: 3, step: 50) // Avg time/img: 0.1312 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m13.58\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 231.5 (epoch: 4, step: 0) // Avg time/img: 0.1436 s\n",
            "loss: 199.2 (epoch: 4, step: 50) // Avg time/img: 0.1345 s\n",
            "loss: 196.8 (epoch: 4, step: 100) // Avg time/img: 0.1340 s\n",
            "loss: 196.3 (epoch: 4, step: 150) // Avg time/img: 0.1338 s\n",
            "loss: 196.3 (epoch: 4, step: 200) // Avg time/img: 0.1337 s\n",
            "loss: 194.5 (epoch: 4, step: 250) // Avg time/img: 0.1337 s\n",
            "loss: 194.2 (epoch: 4, step: 300) // Avg time/img: 0.1336 s\n",
            "loss: 193.2 (epoch: 4, step: 350) // Avg time/img: 0.1336 s\n",
            "loss: 193.3 (epoch: 4, step: 400) // Avg time/img: 0.1335 s\n",
            "loss: 193.5 (epoch: 4, step: 450) // Avg time/img: 0.1335 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "162.68125915527344\n",
            "1\n",
            "VAL loss: 162.7 (epoch: 4, step: 0) // Avg time/img: 0.1437 s\n",
            "9697.531425476074\n",
            "51\n",
            "VAL loss: 190.1 (epoch: 4, step: 50) // Avg time/img: 0.1315 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m14.13\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 112.5 (epoch: 5, step: 0) // Avg time/img: 0.1437 s\n",
            "loss: 187.0 (epoch: 5, step: 50) // Avg time/img: 0.1345 s\n",
            "loss: 188.7 (epoch: 5, step: 100) // Avg time/img: 0.1342 s\n",
            "loss: 188.1 (epoch: 5, step: 150) // Avg time/img: 0.1340 s\n",
            "loss: 191.5 (epoch: 5, step: 200) // Avg time/img: 0.1338 s\n",
            "loss: 191.8 (epoch: 5, step: 250) // Avg time/img: 0.1337 s\n",
            "loss: 192.1 (epoch: 5, step: 300) // Avg time/img: 0.1337 s\n",
            "loss: 191.9 (epoch: 5, step: 350) // Avg time/img: 0.1336 s\n",
            "loss: 192.6 (epoch: 5, step: 400) // Avg time/img: 0.1336 s\n",
            "loss: 192.7 (epoch: 5, step: 450) // Avg time/img: 0.1336 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "164.1888885498047\n",
            "1\n",
            "VAL loss: 164.2 (epoch: 5, step: 0) // Avg time/img: 0.1444 s\n",
            "9693.22737121582\n",
            "51\n",
            "VAL loss: 190.1 (epoch: 5, step: 50) // Avg time/img: 0.1319 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m15.30\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 160.6 (epoch: 6, step: 0) // Avg time/img: 0.1473 s\n",
            "loss: 196.0 (epoch: 6, step: 50) // Avg time/img: 0.1346 s\n",
            "loss: 191.7 (epoch: 6, step: 100) // Avg time/img: 0.1340 s\n",
            "loss: 192.5 (epoch: 6, step: 150) // Avg time/img: 0.1338 s\n",
            "loss: 192.8 (epoch: 6, step: 200) // Avg time/img: 0.1336 s\n",
            "loss: 194.2 (epoch: 6, step: 250) // Avg time/img: 0.1336 s\n",
            "loss: 193.7 (epoch: 6, step: 300) // Avg time/img: 0.1336 s\n",
            "loss: 192.1 (epoch: 6, step: 350) // Avg time/img: 0.1336 s\n",
            "loss: 192.2 (epoch: 6, step: 400) // Avg time/img: 0.1336 s\n",
            "loss: 191.9 (epoch: 6, step: 450) // Avg time/img: 0.1336 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "166.19699096679688\n",
            "1\n",
            "VAL loss: 166.2 (epoch: 6, step: 0) // Avg time/img: 0.1423 s\n",
            "9772.97232055664\n",
            "51\n",
            "VAL loss: 191.6 (epoch: 6, step: 50) // Avg time/img: 0.1314 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m14.76\u001b[0m %\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 217.8 (epoch: 7, step: 0) // Avg time/img: 0.1441 s\n",
            "loss: 190.8 (epoch: 7, step: 50) // Avg time/img: 0.1342 s\n",
            "loss: 189.6 (epoch: 7, step: 100) // Avg time/img: 0.1337 s\n",
            "loss: 191.0 (epoch: 7, step: 150) // Avg time/img: 0.1335 s\n",
            "loss: 192.6 (epoch: 7, step: 200) // Avg time/img: 0.1335 s\n",
            "loss: 191.3 (epoch: 7, step: 250) // Avg time/img: 0.1335 s\n",
            "loss: 190.7 (epoch: 7, step: 300) // Avg time/img: 0.1334 s\n",
            "loss: 190.4 (epoch: 7, step: 350) // Avg time/img: 0.1334 s\n",
            "loss: 191.2 (epoch: 7, step: 400) // Avg time/img: 0.1333 s\n",
            "loss: 190.8 (epoch: 7, step: 450) // Avg time/img: 0.1333 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "162.4380340576172\n",
            "1\n",
            "VAL loss: 162.4 (epoch: 7, step: 0) // Avg time/img: 0.1404 s\n",
            "9583.654167175293\n",
            "51\n",
            "VAL loss: 187.9 (epoch: 7, step: 50) // Avg time/img: 0.1309 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m18.33\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 212.0 (epoch: 8, step: 0) // Avg time/img: 0.1432 s\n",
            "loss: 192.9 (epoch: 8, step: 50) // Avg time/img: 0.1336 s\n",
            "loss: 191.8 (epoch: 8, step: 100) // Avg time/img: 0.1332 s\n",
            "loss: 191.7 (epoch: 8, step: 150) // Avg time/img: 0.1335 s\n",
            "loss: 191.0 (epoch: 8, step: 200) // Avg time/img: 0.1334 s\n",
            "loss: 191.4 (epoch: 8, step: 250) // Avg time/img: 0.1334 s\n",
            "loss: 190.0 (epoch: 8, step: 300) // Avg time/img: 0.1334 s\n",
            "loss: 190.0 (epoch: 8, step: 350) // Avg time/img: 0.1334 s\n",
            "loss: 189.7 (epoch: 8, step: 400) // Avg time/img: 0.1334 s\n",
            "loss: 190.2 (epoch: 8, step: 450) // Avg time/img: 0.1334 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "161.41000366210938\n",
            "1\n",
            "VAL loss: 161.4 (epoch: 8, step: 0) // Avg time/img: 0.1402 s\n",
            "9544.068260192871\n",
            "51\n",
            "VAL loss: 187.1 (epoch: 8, step: 50) // Avg time/img: 0.1312 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m19.18\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 177.1 (epoch: 9, step: 0) // Avg time/img: 0.1433 s\n",
            "loss: 189.2 (epoch: 9, step: 50) // Avg time/img: 0.1344 s\n",
            "loss: 192.4 (epoch: 9, step: 100) // Avg time/img: 0.1339 s\n",
            "loss: 190.4 (epoch: 9, step: 150) // Avg time/img: 0.1338 s\n",
            "loss: 191.1 (epoch: 9, step: 200) // Avg time/img: 0.1336 s\n",
            "loss: 190.6 (epoch: 9, step: 250) // Avg time/img: 0.1335 s\n",
            "loss: 189.5 (epoch: 9, step: 300) // Avg time/img: 0.1335 s\n",
            "loss: 189.1 (epoch: 9, step: 350) // Avg time/img: 0.1334 s\n",
            "loss: 189.7 (epoch: 9, step: 400) // Avg time/img: 0.1334 s\n",
            "loss: 189.0 (epoch: 9, step: 450) // Avg time/img: 0.1334 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "159.96693420410156\n",
            "1\n",
            "VAL loss: 160.0 (epoch: 9, step: 0) // Avg time/img: 0.1432 s\n",
            "9549.681915283203\n",
            "51\n",
            "VAL loss: 187.2 (epoch: 9, step: 50) // Avg time/img: 0.1311 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m19.25\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 221.6 (epoch: 10, step: 0) // Avg time/img: 0.1474 s\n",
            "loss: 186.4 (epoch: 10, step: 50) // Avg time/img: 0.1347 s\n",
            "loss: 188.4 (epoch: 10, step: 100) // Avg time/img: 0.1338 s\n",
            "loss: 187.0 (epoch: 10, step: 150) // Avg time/img: 0.1334 s\n",
            "loss: 186.7 (epoch: 10, step: 200) // Avg time/img: 0.1334 s\n",
            "loss: 187.2 (epoch: 10, step: 250) // Avg time/img: 0.1334 s\n",
            "loss: 187.6 (epoch: 10, step: 300) // Avg time/img: 0.1335 s\n",
            "loss: 188.2 (epoch: 10, step: 350) // Avg time/img: 0.1334 s\n",
            "loss: 188.2 (epoch: 10, step: 400) // Avg time/img: 0.1334 s\n",
            "loss: 188.4 (epoch: 10, step: 450) // Avg time/img: 0.1334 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "161.09820556640625\n",
            "1\n",
            "VAL loss: 161.1 (epoch: 10, step: 0) // Avg time/img: 0.1525 s\n",
            "9504.519096374512\n",
            "51\n",
            "VAL loss: 186.4 (epoch: 10, step: 50) // Avg time/img: 0.1314 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m20.18\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_encoder_best.pth (epoch: 10)\n",
            "========== DECODER TRAINING ===========\n",
            "transform\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/train\n",
            "/content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training/leftImg8bit/val\n",
            "calcolo weights\n",
            "calcolo loader\n",
            "fine loader_val\n",
            "inizio optimizer\n",
            "fine optimizer\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  0.0005\n",
            "loss: 230.2 (epoch: 1, step: 0) // Avg time/img: 0.1969 s\n",
            "loss: 215.3 (epoch: 1, step: 50) // Avg time/img: 0.1778 s\n",
            "loss: 208.6 (epoch: 1, step: 100) // Avg time/img: 0.1769 s\n",
            "loss: 209.9 (epoch: 1, step: 150) // Avg time/img: 0.1770 s\n",
            "loss: 211.4 (epoch: 1, step: 200) // Avg time/img: 0.1768 s\n",
            "loss: 210.7 (epoch: 1, step: 250) // Avg time/img: 0.1767 s\n",
            "loss: 209.1 (epoch: 1, step: 300) // Avg time/img: 0.1767 s\n",
            "loss: 208.4 (epoch: 1, step: 350) // Avg time/img: 0.1766 s\n",
            "loss: 206.9 (epoch: 1, step: 400) // Avg time/img: 0.1765 s\n",
            "loss: 206.7 (epoch: 1, step: 450) // Avg time/img: 0.1764 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "164.51123046875\n",
            "1\n",
            "VAL loss: 164.5 (epoch: 1, step: 0) // Avg time/img: 0.1852 s\n",
            "10239.990447998047\n",
            "51\n",
            "VAL loss: 200.8 (epoch: 1, step: 50) // Avg time/img: 0.1716 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m7.77\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  0.00045476628804148113\n",
            "loss: 236.0 (epoch: 2, step: 0) // Avg time/img: 0.1917 s\n",
            "loss: 209.4 (epoch: 2, step: 50) // Avg time/img: 0.1777 s\n",
            "loss: 205.4 (epoch: 2, step: 100) // Avg time/img: 0.1764 s\n",
            "loss: 204.6 (epoch: 2, step: 150) // Avg time/img: 0.1761 s\n",
            "loss: 203.0 (epoch: 2, step: 200) // Avg time/img: 0.1761 s\n",
            "loss: 203.0 (epoch: 2, step: 250) // Avg time/img: 0.1760 s\n",
            "loss: 203.7 (epoch: 2, step: 300) // Avg time/img: 0.1760 s\n",
            "loss: 202.9 (epoch: 2, step: 350) // Avg time/img: 0.1759 s\n",
            "loss: 202.3 (epoch: 2, step: 400) // Avg time/img: 0.1759 s\n",
            "loss: 202.4 (epoch: 2, step: 450) // Avg time/img: 0.1759 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "163.41720581054688\n",
            "1\n",
            "VAL loss: 163.4 (epoch: 2, step: 0) // Avg time/img: 0.1859 s\n",
            "10077.185920715332\n",
            "51\n",
            "VAL loss: 197.6 (epoch: 2, step: 50) // Avg time/img: 0.1716 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m10.73\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  0.00040902607302542923\n",
            "loss: 228.0 (epoch: 3, step: 0) // Avg time/img: 0.1936 s\n",
            "loss: 196.1 (epoch: 3, step: 50) // Avg time/img: 0.1768 s\n",
            "loss: 194.9 (epoch: 3, step: 100) // Avg time/img: 0.1761 s\n",
            "loss: 198.1 (epoch: 3, step: 150) // Avg time/img: 0.1759 s\n",
            "loss: 200.8 (epoch: 3, step: 200) // Avg time/img: 0.1759 s\n",
            "loss: 200.5 (epoch: 3, step: 250) // Avg time/img: 0.1758 s\n",
            "loss: 201.8 (epoch: 3, step: 300) // Avg time/img: 0.1757 s\n",
            "loss: 202.1 (epoch: 3, step: 350) // Avg time/img: 0.1758 s\n",
            "loss: 201.6 (epoch: 3, step: 400) // Avg time/img: 0.1758 s\n",
            "loss: 201.1 (epoch: 3, step: 450) // Avg time/img: 0.1757 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "147.38623046875\n",
            "1\n",
            "VAL loss: 147.4 (epoch: 3, step: 0) // Avg time/img: 0.1870 s\n",
            "9961.655067443848\n",
            "51\n",
            "VAL loss: 195.3 (epoch: 3, step: 50) // Avg time/img: 0.1713 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m11.53\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  0.00036270892346860996\n",
            "loss: 181.1 (epoch: 4, step: 0) // Avg time/img: 0.1912 s\n",
            "loss: 196.1 (epoch: 4, step: 50) // Avg time/img: 0.1772 s\n",
            "loss: 193.9 (epoch: 4, step: 100) // Avg time/img: 0.1762 s\n",
            "loss: 196.2 (epoch: 4, step: 150) // Avg time/img: 0.1759 s\n",
            "loss: 198.0 (epoch: 4, step: 200) // Avg time/img: 0.1758 s\n",
            "loss: 197.1 (epoch: 4, step: 250) // Avg time/img: 0.1758 s\n",
            "loss: 196.0 (epoch: 4, step: 300) // Avg time/img: 0.1758 s\n",
            "loss: 196.2 (epoch: 4, step: 350) // Avg time/img: 0.1758 s\n",
            "loss: 196.9 (epoch: 4, step: 400) // Avg time/img: 0.1757 s\n",
            "loss: 197.2 (epoch: 4, step: 450) // Avg time/img: 0.1758 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "148.88720703125\n",
            "1\n",
            "VAL loss: 148.9 (epoch: 4, step: 0) // Avg time/img: 0.1885 s\n",
            "9874.935485839844\n",
            "51\n",
            "VAL loss: 193.6 (epoch: 4, step: 50) // Avg time/img: 0.1718 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m11.94\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  0.00031572293374467766\n",
            "loss: 232.6 (epoch: 5, step: 0) // Avg time/img: 0.1872 s\n",
            "loss: 203.7 (epoch: 5, step: 50) // Avg time/img: 0.1769 s\n",
            "loss: 199.1 (epoch: 5, step: 100) // Avg time/img: 0.1760 s\n",
            "loss: 201.0 (epoch: 5, step: 150) // Avg time/img: 0.1758 s\n",
            "loss: 199.3 (epoch: 5, step: 200) // Avg time/img: 0.1758 s\n",
            "loss: 198.6 (epoch: 5, step: 250) // Avg time/img: 0.1757 s\n",
            "loss: 197.9 (epoch: 5, step: 300) // Avg time/img: 0.1757 s\n",
            "loss: 198.2 (epoch: 5, step: 350) // Avg time/img: 0.1757 s\n",
            "loss: 197.5 (epoch: 5, step: 400) // Avg time/img: 0.1757 s\n",
            "loss: 197.3 (epoch: 5, step: 450) // Avg time/img: 0.1757 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "150.73126220703125\n",
            "1\n",
            "VAL loss: 150.7 (epoch: 5, step: 0) // Avg time/img: 0.1923 s\n",
            "9820.578979492188\n",
            "51\n",
            "VAL loss: 192.6 (epoch: 5, step: 50) // Avg time/img: 0.1717 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m12.32\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  0.0002679433656340733\n",
            "loss: 232.4 (epoch: 6, step: 0) // Avg time/img: 0.1902 s\n",
            "loss: 194.2 (epoch: 6, step: 50) // Avg time/img: 0.1773 s\n",
            "loss: 193.9 (epoch: 6, step: 100) // Avg time/img: 0.1765 s\n",
            "loss: 192.8 (epoch: 6, step: 150) // Avg time/img: 0.1762 s\n",
            "loss: 192.3 (epoch: 6, step: 200) // Avg time/img: 0.1760 s\n",
            "loss: 193.4 (epoch: 6, step: 250) // Avg time/img: 0.1760 s\n",
            "loss: 192.9 (epoch: 6, step: 300) // Avg time/img: 0.1759 s\n",
            "loss: 193.2 (epoch: 6, step: 350) // Avg time/img: 0.1759 s\n",
            "loss: 193.0 (epoch: 6, step: 400) // Avg time/img: 0.1758 s\n",
            "loss: 192.5 (epoch: 6, step: 450) // Avg time/img: 0.1758 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "150.127197265625\n",
            "1\n",
            "VAL loss: 150.1 (epoch: 6, step: 0) // Avg time/img: 0.1955 s\n",
            "9759.524803161621\n",
            "51\n",
            "VAL loss: 191.4 (epoch: 6, step: 50) // Avg time/img: 0.1720 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m13.32\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  0.00021919164527704348\n",
            "loss: 223.0 (epoch: 7, step: 0) // Avg time/img: 0.1952 s\n",
            "loss: 189.9 (epoch: 7, step: 50) // Avg time/img: 0.1770 s\n",
            "loss: 191.4 (epoch: 7, step: 100) // Avg time/img: 0.1762 s\n",
            "loss: 189.5 (epoch: 7, step: 150) // Avg time/img: 0.1761 s\n",
            "loss: 189.5 (epoch: 7, step: 200) // Avg time/img: 0.1759 s\n",
            "loss: 188.5 (epoch: 7, step: 250) // Avg time/img: 0.1758 s\n",
            "loss: 189.0 (epoch: 7, step: 300) // Avg time/img: 0.1758 s\n",
            "loss: 189.6 (epoch: 7, step: 350) // Avg time/img: 0.1758 s\n",
            "loss: 190.7 (epoch: 7, step: 400) // Avg time/img: 0.1758 s\n",
            "loss: 190.6 (epoch: 7, step: 450) // Avg time/img: 0.1757 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "150.9278564453125\n",
            "1\n",
            "VAL loss: 150.9 (epoch: 7, step: 0) // Avg time/img: 0.1871 s\n",
            "9706.179931640625\n",
            "51\n",
            "VAL loss: 190.3 (epoch: 7, step: 50) // Avg time/img: 0.1721 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m13.16\u001b[0m %\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  0.00016919173095082495\n",
            "loss: 229.2 (epoch: 8, step: 0) // Avg time/img: 0.1864 s\n",
            "loss: 191.4 (epoch: 8, step: 50) // Avg time/img: 0.1768 s\n",
            "loss: 191.6 (epoch: 8, step: 100) // Avg time/img: 0.1763 s\n",
            "loss: 191.1 (epoch: 8, step: 150) // Avg time/img: 0.1761 s\n",
            "loss: 191.4 (epoch: 8, step: 200) // Avg time/img: 0.1761 s\n",
            "loss: 192.4 (epoch: 8, step: 250) // Avg time/img: 0.1761 s\n",
            "loss: 190.9 (epoch: 8, step: 300) // Avg time/img: 0.1760 s\n",
            "loss: 190.0 (epoch: 8, step: 350) // Avg time/img: 0.1760 s\n",
            "loss: 189.6 (epoch: 8, step: 400) // Avg time/img: 0.1760 s\n",
            "loss: 188.9 (epoch: 8, step: 450) // Avg time/img: 0.1759 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "150.606201171875\n",
            "1\n",
            "VAL loss: 150.6 (epoch: 8, step: 0) // Avg time/img: 0.1881 s\n",
            "9669.155433654785\n",
            "51\n",
            "VAL loss: 189.6 (epoch: 8, step: 50) // Avg time/img: 0.1718 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m14.54\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  0.00011746189430880188\n",
            "loss: 198.1 (epoch: 9, step: 0) // Avg time/img: 0.1914 s\n",
            "loss: 182.4 (epoch: 9, step: 50) // Avg time/img: 0.1777 s\n",
            "loss: 185.0 (epoch: 9, step: 100) // Avg time/img: 0.1765 s\n",
            "loss: 186.1 (epoch: 9, step: 150) // Avg time/img: 0.1763 s\n",
            "loss: 186.1 (epoch: 9, step: 200) // Avg time/img: 0.1763 s\n",
            "loss: 186.0 (epoch: 9, step: 250) // Avg time/img: 0.1762 s\n",
            "loss: 185.1 (epoch: 9, step: 300) // Avg time/img: 0.1761 s\n",
            "loss: 185.1 (epoch: 9, step: 350) // Avg time/img: 0.1761 s\n",
            "loss: 185.0 (epoch: 9, step: 400) // Avg time/img: 0.1760 s\n",
            "loss: 185.3 (epoch: 9, step: 450) // Avg time/img: 0.1760 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "150.22140502929688\n",
            "1\n",
            "VAL loss: 150.2 (epoch: 9, step: 0) // Avg time/img: 0.1999 s\n",
            "9612.005508422852\n",
            "51\n",
            "VAL loss: 188.5 (epoch: 9, step: 50) // Avg time/img: 0.1722 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m15.40\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  6.294627058970836e-05\n",
            "loss: 194.8 (epoch: 10, step: 0) // Avg time/img: 0.1883 s\n",
            "loss: 182.4 (epoch: 10, step: 50) // Avg time/img: 0.1771 s\n",
            "loss: 184.5 (epoch: 10, step: 100) // Avg time/img: 0.1765 s\n",
            "loss: 187.2 (epoch: 10, step: 150) // Avg time/img: 0.1762 s\n",
            "loss: 185.2 (epoch: 10, step: 200) // Avg time/img: 0.1762 s\n",
            "loss: 185.6 (epoch: 10, step: 250) // Avg time/img: 0.1761 s\n",
            "loss: 186.6 (epoch: 10, step: 300) // Avg time/img: 0.1761 s\n",
            "loss: 186.3 (epoch: 10, step: 350) // Avg time/img: 0.1760 s\n",
            "loss: 186.3 (epoch: 10, step: 400) // Avg time/img: 0.1760 s\n",
            "loss: 186.5 (epoch: 10, step: 450) // Avg time/img: 0.1760 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "143.80294799804688\n",
            "1\n",
            "VAL loss: 143.8 (epoch: 10, step: 0) // Avg time/img: 0.1876 s\n",
            "9570.696304321289\n",
            "51\n",
            "VAL loss: 187.7 (epoch: 10, step: 50) // Avg time/img: 0.1717 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m15.92\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/jacc_focal_loss/model_best.pth (epoch: 10)\n",
            "========== TRAINING FINISHED ===========\n"
          ]
        }
      ],
      "source": [
        "# Training with jaccard loss with focal loss\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/train\n",
        "!python main.py  --savedir jacc_focal_loss --datadir /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training --num-epochs 10 --batch-size 6 --lossfunction jaccard_loss --onlyone False --focal_loss True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with jacc loss with cross_entropy\n",
        "%cd /content/AnomalySegmentation_CourseProjectBaseCode/train\n",
        "!python main.py --resume  --savedir jacc_cross_entropy --datadir /content/AnomalySegmentation_CourseProjectBaseCode/Cityscapes_training --num-epochs 10 --batch-size 6 --lossfunction jaccard_loss --onlyone False\n"
      ],
      "metadata": {
        "id": "f_FZKTbxKZnI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}